{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tercer_Entregable_Daniel_Quinones.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOxgGRlE+Pe2dnwiTh6ZM9L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danquio194/github-slideshow/blob/master/Tercer_Entregable_Daniel_Quinones.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0-0Dyqi2kV1"
      },
      "source": [
        "**Second Problems' Set -  Machine Learning Introduction**\n",
        "\n",
        "*by Daniel Felipe Quiñones Ordoñez*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9WHEJfg2jQX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N__K2xIX3FqK"
      },
      "source": [
        "**Exercise 2.2** \n",
        "\n",
        "(a). Verify the bound of Theorem 2.4 in the three cases of Example 2.2\n",
        "  \n",
        "  (i) Positive Rays: $H$ consists of all hypothesis in one dimension of the form $h(x) = sign(x-a)$\n",
        "\n",
        "  (ii) Positive Intervals: $H$ consists of all hypothesis in one dimension that are positive within some interval and negative elsewhere.\n",
        "  \n",
        "  (iii) Convex Sets: $H$ consists of all hypothesis in two dimensions that are positive inside some convex set and negative elsewhere.\n",
        "\n",
        "(Note: you can use the break points you find in Exercise 2.1)\n",
        "\n",
        "(b). Does there exist a hypothesis set for which $m_{H}(N) = N + 2^{\\lfloor N/2 \\rfloor} $ (where) $\\lfloor N/2 \\rfloor$ is the largest integer $\\leq N/2$. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh5Iu5tTM_zn"
      },
      "source": [
        "(a). (i) We know that for this $H$, $m_{H}(N) = N + 1$. Also is easy to see that the break point for this hypothesis set is $k = 2$. Let's see the minimum case in which the bound of Theorem $2.4$ holds, for any set of $N$ points \n",
        "\n",
        "\\begin{align*}\n",
        "  m_{H}(N) &= N + 1 \\\\\n",
        "           &\\leq \\sum_{i = 0}^{1} \\binom{N}{i} \\\\\n",
        "           &= \\binom{N}{0} + \\binom{N}{1} \\\\\n",
        "           &= N + 1 \n",
        "\\end{align*}\n",
        "\n",
        "(ii) Rasoning in an analogous way, knowing that this set of hypothesis $m_{H}(N) = \\binom{N + 1}{2} + 1$ and its break point $k = 2$, we get\n",
        "\n",
        "\\begin{align*}\n",
        "  m_{H}(N) &=  \\binom{N + 1}{2} + 1\\\\\n",
        "           &= \\frac{N(N + 1)}{2} + 1 \\\\\n",
        "           &\\leq \\sum_{i = 0}^{2} \\binom{N}{i} \\\\\n",
        "           &= \\binom{N}{0} + \\binom{N}{1} + \\binom{N}{2} \\\\\n",
        "           &= \\frac{N(N + 1)}{2}\n",
        "\\end{align*}\n",
        "\n",
        "(iii) Our $m_{H} (N) = 2^{N}$ for this set of hypothesis. In this case we have the particularity that the break point is $k = \\infty$. There we get directly the inequality \n",
        "\n",
        "\\begin{align*}\n",
        " m_{H} (N) &= 2^{N} \\\\\n",
        "           &\\leq  \\sum_{i = 0}^{\\infty} \\binom{N}{i} \\\\\n",
        "           &= 2^{N} \n",
        "\\end{align*}\n",
        "\n",
        "for definition of combinations.\n",
        "\n",
        "(b). Let us suppose that there is a hypothesis such that \n",
        "\n",
        "\\begin{align*}\n",
        "  m_{H}(N) = N + 2^{\\lfloor N/2 \\rfloor}  \n",
        "\\end{align*}\n",
        "\n",
        "Then, for $N \\geq 3$, $m_{H}(N) < 2^{N}$. Thus there exist a $k$ break point and for theorem $2.4$ \n",
        "\n",
        "\\begin{align*}\n",
        "  m_{H}(N) = N + 2^{\\lfloor N/2 \\rfloor}  \\leq \\sum_{i = 0}^{k-1} \\binom{N}{i},\n",
        "\\end{align*}\n",
        "\n",
        "that is a contradiction.  To conclude, there ir no hypothesis that holds the initial equality given."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kV3_pOiN5yTV"
      },
      "source": [
        "**Exercise 2.5** \n",
        "\n",
        "Suppose we have a simple learning model whose growth function is $m_{H} (N) = N + 1$, hence $d_{VC} =  1$. Use the VC bound (2.12) to stimate the probability that $E_{out}$ will be within $0.1$ of $E_{in}$ given 100 training examples. [*Hint: The estimate will be ridiculous*.]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB4V1OTJibMx"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "From the formula (2.13) \n",
        "\n",
        "\\begin{equation}\n",
        "N = \\frac{8}{\\epsilon ^{2}} ln(\\frac{4(2N)^{dvc}+1}{\\delta})\n",
        "\\end{equation}\n",
        "\n",
        "we get the next program"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k18LLELZ2jtr",
        "outputId": "cc364794-d00c-44c7-f489-47b3396c674c"
      },
      "source": [
        "#It is enough to compute the delta value with the following function to get the estimate\n",
        "#We can verify that is ridiculous\n",
        "\n",
        "\n",
        "import math\n",
        "\n",
        "def delta(N, eps, dvc):\n",
        "  return (4*(2*N + 1)**dvc) / math.exp((1/8) * (eps**2) * N)\n",
        "\n",
        "print(\"The estimate\" , delta(100, 0.1, 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The estimate 709.5275096780147\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yry4cBmy6wj5"
      },
      "source": [
        "**Exercise 2.6** \n",
        "\n",
        "A data set has $600$ examples. To properly test the performance of the final hypothesis, you set aside a randomly selected subset of $200$ examples which are never used in the training phase; this form a test set. You use a learning model with $1000$ hypothesis and select the final hypothesis $g$ based on the $400$ training examples. We wish to estimate $E_{out}(g)$. We have access to two estimates: $E_{in}(g)$,  the in-sample error on the $400$ training examples; and, $E_{test}(g)$, the test error on the $200$ test examples that were set aside.\n",
        "\n",
        "(a). Using a $5\\%$ error tolerance ($\\delta = 0.05$), which estimate has the higher 'error bar'?\n",
        "\n",
        "(b). Is there any reason we shouldn't reserve even more examples for testing?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vmw6_sSDjhHJ"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "(a). Firstly we obtain the $\\epsilon$ estimate from the formula $\\epsilon = \\sqrt{\\frac{8}{N} ln(\\frac{4M}{\\delta})}$. In such way we know the $E_{in}(g)$ to get the $g- function$. Once we know that, we can use Hoeffding to compute the $E_{test}(g)$, because we have only one hypothesis and Hoeffding generalize out of the set of training points. Now, knowing both values we can observe that the $E_{in}(g)$  is so much higuer than the $E_{test}(g)$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-23XiD3FgHIg",
        "outputId": "a76359c3-db28-44e0-ba30-146492d843b2"
      },
      "source": [
        "def Hoeffding(eps, N):\n",
        "  return 2*math.exp(-2 * (eps**2) * N)\n",
        "\n",
        "def epsilon(delta, N, M):\n",
        "  return math.sqrt((8/N) * math.log((4 * M  )/ delta))\n",
        "\n",
        "e_in = epsilon(0.05, 400, 1000)\n",
        "print(\"This is the E_in error estimate: \", e_in)                   #Error in the training\n",
        "print(\"This is the E_test error estimate: \", Hoeffding(e_in, 200))  #Error in test"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is the E_in error estimate:  0.4751795852865739\n",
            "This is the E_test error estimate:  1.1920928955078186e-39\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llS4qZjBmgyE"
      },
      "source": [
        "(b). As we can see, from the previous code, the value $E_{test}(g)$ is within the error tolerance.- Actually is pretty lower than the bound choosen-with the numbers of test points. So, it is not necessary to increase the training set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubmWMkjRAcbZ"
      },
      "source": [
        "**Problem 2.1** In equation (2.1), set ($\\delta = 0.03$) and let \n",
        "\n",
        "\\begin{equation}\n",
        "  \\epsilon (M, N, \\delta) = \\sqrt{\\frac{1}{2N} ln \\frac{2M}{\\delta}}.\n",
        "\\end{equation}\n",
        "\n",
        "(a). For $M = 1$, how many examples do we need to make $\\epsilon \\leq 0.05$?\n",
        "\n",
        "(b). For $M = 100$, how many examples do we need to make $\\epsilon \\leq 0.05$? \n",
        "\n",
        "(c). For $M = 10000$, how many examples do we need to make $\\epsilon \\leq 0.05$? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBSGncVOopnV"
      },
      "source": [
        "**Solution**\n",
        "\n",
        "From the formula we free the $N$ variable and we replace the values of $\\epsilon, \\delta$ and $M$ in each case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7pUmNVNivPQ",
        "outputId": "cd2467f4-3549-4340-e304-0fab991664c9"
      },
      "source": [
        "def samples(eps, delta, M):\n",
        "  return (1/ (2 * eps**2)) * math.log( (2 * M) / delta)\n",
        "\n",
        "print(\"Samples required: \", samples(0.05, 0.03, 1))\n",
        "\n",
        "print(\"Samples required: \", samples(0.05, 0.03, 100))\n",
        "\n",
        "print(\"Samples required: \", samples(0.05, 0.03, 1000))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Samples required:  839.9410155759854\n",
            "Samples required:  1760.9750527736035\n",
            "Samples required:  2221.4920713724127\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BK6mu3UWB5uS"
      },
      "source": [
        "**Problem 2.12** \n",
        "\n",
        "For an $H$ with $d_{VC} = 10$, what sample size do you need (as prescribed by the generalization bound) to have a $95\\%$ confidence that your generalization error is at most $0.05$?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m86pNmeIix5I",
        "outputId": "7a5cff84-154e-422e-946f-f715888492da"
      },
      "source": [
        "#number of samples depending on the dvc dimension\n",
        "def samples_dvc(eps, delta, dvc, N_init):\n",
        "  return (8/ (eps**2)) * math.log( (4 * ((2 * N_init)**dvc) + 4) / delta)\n",
        "\n",
        "#generalization error bound\n",
        "def epsilon(delta, N, dvc):\n",
        "  return math.sqrt((8/N) * math.log((4 * ((2 * N)**dvc) + 4 )/ delta))\n",
        "\n",
        "N = 1000    #initial samples size\n",
        "g_error = 1 #maximum bound of the generalization error initialized in 1\n",
        "\n",
        "\n",
        "#Loop to obtain the sample size required\n",
        "#It will stop when we get the samples that hold the conditions\n",
        "while (g_error > 0.05):\n",
        "  N = samples_dvc(0.05, 0.05, 10, N)\n",
        "  g_error = epsilon(0.05, N, 10)\n",
        "  print(\"Sample size \", N, \"Generalization error \", g_error) #WE print the values of each iteration\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample size  257251.363936303 Generalization error  0.06500734622588701\n",
            "Sample size  434853.0815903086 Generalization error  0.05095660883672775\n",
            "Sample size  451651.62731454166 Generalization error  0.05006709153900405\n",
            "Sample size  452864.5206285506 Generalization error  0.050004737373750184\n",
            "Sample size  452950.34023365 Generalization error  0.05000033466863365\n",
            "Sample size  452956.40378480166 Generalization error  0.050000023643242075\n",
            "Sample size  452956.83215921914 Generalization error  0.050000001670321544\n",
            "Sample size  452956.8624225618 Generalization error  0.05000000011800305\n",
            "Sample size  452956.8645605733 Generalization error  0.05000000000833655\n",
            "Sample size  452956.8647116172 Generalization error  0.050000000000588955\n",
            "Sample size  452956.86472228804 Generalization error  0.050000000000041615\n",
            "Sample size  452956.8647230419 Generalization error  0.050000000000002945\n",
            "Sample size  452956.8647230951 Generalization error  0.05000000000000021\n",
            "Sample size  452956.8647230988 Generalization error  0.05000000000000002\n",
            "Sample size  452956.8647230991 Generalization error  0.05000000000000001\n",
            "Sample size  452956.8647230992 Generalization error  0.05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgvByMITCx5F"
      },
      "source": [
        "**Problem 2.16**\n",
        "\n",
        "In this problem we will consider $\\mathcal{X} = \\mathbb{R}$. That is, $\\textbf{x} = x$ is a one dimensional variable. For a hypothesis set\n",
        "\n",
        "\\begin{equation}\n",
        "  H = \\{ h_{c} | h_{x} = sign(\\sum_{i = 0}^{D} c_{i} x^{i}) \\} ,\n",
        "\\end{equation}\n",
        "\n",
        "prove that the VC dimension of $H$ is exactly $(D + 1)$ by showing that,\n",
        "\n",
        "(a). There are $D + 1$ points which are shattered by $H$.\n",
        "\n",
        "\n",
        "(b). There are no $D + 2$ points which are shattered by $H$."
      ]
    }
  ]
}